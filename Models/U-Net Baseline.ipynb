{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# U-Net Baseline Single-coil\n",
    "\n",
    "This baseline is from [fastMRI](https://arxiv.org/abs/1811.08839), reproduced by myself.\n",
    "\n",
    "The original U-Net paper: [U-Net: Convolutional networks for biomedical image segmentation (O. Ronneberger et al., 2015)](https://doi.org/10.1007/978-3-319-24574-4_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement U_Net model.\n",
    "\n",
    "![U-Net](../imgs/unet.png)\n",
    "\n",
    "First, we create `ConvBlock`:\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by instance normalization, LeakyReLU activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_c:int, out_c:int, drop_prob:float):\n",
    "        \"\"\"\n",
    "        :param in_c: input channels to the ConvBlock\n",
    "        :param out_c: output channels to the ConvBlock\n",
    "        :param drop_prob: Dropout probability\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.in_c = in_c\n",
    "        self.out_c = out_c\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(self.in_c,\n",
    "                      self.out_c,\n",
    "                      kernel_size=3,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.InstanceNorm2d(self.out_c),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Dropout2d(self.drop_prob),\n",
    "            nn.Conv2d(self.out_c,\n",
    "                      self.out_c,\n",
    "                      kernel_size=3,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.InstanceNorm2d(self.out_c),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "            nn.Dropout2d(self.drop_prob),\n",
    "        )\n",
    "    def forward(self, image: torch.Tensor)-> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param image: Input 4D tensor of shape `(N, in_c, H, W)`\n",
    "        :return: Output tensor of shape `(N, out_c, H, W)`\n",
    "        \"\"\"\n",
    "\n",
    "        result = self.layers(image)\n",
    "        print(result.shape)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then add a `ConvBlock` mirror module `TransposeConvBlock`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class TransposeConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transpose Convolutional Block that consists of one convolution transpose layers followed by instance normalization and LeakyReLU activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_c:int, out_c:int):\n",
    "        \"\"\"\n",
    "        :param in_c: Number of channels in the input.\n",
    "        :param out_c: Number of channels in the output.\n",
    "        \"\"\"\n",
    "        super(TransposeConvBlock, self).__init__()\n",
    "\n",
    "        self.in_c = in_c\n",
    "        self.out_c = out_c\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                self.in_c,\n",
    "                self.out_c,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.InstanceNorm2d(self.out_c),\n",
    "            nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param image: Input 4D tensor of shape `(N, in_c, H, W)`.\n",
    "        :return: Output tensor of shape `(N, out_c, H*2, W*2)`.\n",
    "        \"\"\"\n",
    "        result = self.layers(image)\n",
    "        print(result.shape)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, the whole U-Net model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of a U-Net model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_c, out_c, feats:int=32, num_pool_layers:int=4, drop_prob:float=0.0):\n",
    "        \"\"\"\n",
    "        :param in_c: input channels to the U-Net model\n",
    "        :param out_c: output channels to the U-Net model\n",
    "        :param feats: number of output channels of the first conv layers\n",
    "        :param num_pool_layers: number of down-sampling and up-sampling layers\n",
    "        :param drop_prob: Dropout probability\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        self.in_c = in_c\n",
    "        self.out_c = out_c\n",
    "        self.feats = feats\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.down_sample_layers = nn.ModuleList(\n",
    "            [ConvBlock(self.in_c, self.feats, self.drop_prob)]\n",
    "        )\n",
    "        tmp_ch = self.feats\n",
    "        for _ in range(self.num_pool_layers - 1):\n",
    "            self.down_sample_layers.append(ConvBlock(\n",
    "                tmp_ch,\n",
    "                tmp_ch * 2,\n",
    "                self.drop_prob\n",
    "            ))\n",
    "            tmp_ch *= 2\n",
    "\n",
    "        self.conv = ConvBlock(tmp_ch, tmp_ch * 2, drop_prob)\n",
    "\n",
    "        self.up_conv = nn.ModuleList()\n",
    "        self.up_transpose_conv = nn.ModuleList()\n",
    "        for _ in range(num_pool_layers - 1):\n",
    "            self.up_transpose_conv.append(TransposeConvBlock(\n",
    "                tmp_ch * 2,\n",
    "                tmp_ch\n",
    "            ))\n",
    "            self.up_conv.append(ConvBlock(\n",
    "                tmp_ch * 2,\n",
    "                tmp_ch,\n",
    "                self.drop_prob\n",
    "            ))\n",
    "            tmp_ch //= 2\n",
    "\n",
    "        self.up_transpose_conv.append(TransposeConvBlock(\n",
    "            tmp_ch * 2,\n",
    "            tmp_ch\n",
    "        ))\n",
    "\n",
    "        self.up_conv.append(\n",
    "            nn.Sequential(\n",
    "                ConvBlock(tmp_ch *2,\n",
    "                          tmp_ch,\n",
    "                          self.drop_prob),\n",
    "                nn.Conv2d(tmp_ch,\n",
    "                          self.out_c,\n",
    "                          kernel_size=1,\n",
    "                          stride=1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param image: Input 4D tensor of shape `(N, in_c, H, W)`.\n",
    "        :return: Output tensor of shape `(N, out_c, H, W)`.\n",
    "        \"\"\"\n",
    "\n",
    "        stack = []\n",
    "        output = image # 1, 320, 320\n",
    "\n",
    "        # Down sampling\n",
    "        for layer in self.down_sample_layers:\n",
    "            output = layer(output) # 316 -> 154 -> 73 -> 32 -> 12\n",
    "            print(output.shape)\n",
    "            stack.append(output)\n",
    "            output = F.avg_pool2d(output, kernel_size=2, stride=2, padding=0) # 158 -> 77 -> 36 -> 16 -> 6\n",
    "            print(output.shape)\n",
    "\n",
    "        output = self.conv(output)\n",
    "\n",
    "        # Up sampling\n",
    "        for transpose_conv, conv in zip(self.up_transpose_conv, self.up_conv):\n",
    "            downsample_layer = stack.pop()\n",
    "            output = transpose_conv(output)\n",
    "\n",
    "            # reflect pad on the right/bottom if needed to handle odd input dimensions\n",
    "            padding = [0, 0, 0, 0]\n",
    "            if output.shape[-1] != downsample_layer.shape[-1]:\n",
    "                padding[1] = 1\n",
    "            if output.shape[-2] != downsample_layer.shape[-2]:\n",
    "                padding[3] = 1  # padding bottom\n",
    "            if torch.sum(torch.tensor(padding)) != 0:\n",
    "                output = F.pad(output, padding, \"reflect\")\n",
    "\n",
    "            output = torch.cat([output, downsample_layer], dim=1)\n",
    "            output = conv(output)\n",
    "            print(output.shape)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s2287251/RDS/miniconda/envs/pl/lib/python3.9/site-packages/torch/cuda/__init__.py:145: UserWarning: \n",
      "A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "model = Unet(1, 1).cuda()\n",
    "model(torch.rand(1, 1, 320, 320).cuda())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "trusted": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}